#  Multi-Agent Research Assistant

A modular research assistant built with **AutoGen AgentChat**, **Chainlit UI**, and **GitHub-hosted LLMs** on Azure Inference.

It simulates a full AI research pipeline:
- ğŸ“š **Literature Agent** â€“ searches papers from arXiv & web
- ğŸ§¾ **Paper Review Agent** â€“ summarizes, visualizes, and enhances PDFs
- â“ **Q&A Agent** â€“ answers follow-up questions from reviewed content

---

## ğŸš€ Features

- ğŸ” Dynamic academic search with arXiv + DuckDuckGo
- ğŸ“„ Multi-mode PDF review: "rapid", "academic", "visual", "enhanced"
- ğŸ§  Q&A powered by stored context and external search
- ğŸ—‚ Modular agent architecture with AutoGen + Chainlit
- ğŸ§© Pluggable LLMs: `gpt-4o`, `LLaMA`, `Mistral`, or custom deployments

---

## ğŸ› ï¸ Tech Stack

| Layer | Tool |
|-------|------|
| Agents | `autogen-agentchat` |
| Tools  | `autogen-core`, `FunctionTool` |
| LLMs   | GitHub-hosted models on Azure Inference |
| Frontend | `Chainlit` for conversational UI |
| PDF & Web | `PyMuPDF`, `duckduckgo-search`, `matplotlib` |

---

## ğŸ“‚ Project Structure

```
project_root/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ literature_agent.py
â”‚   â”œâ”€â”€ paper_review_agent.py
â”‚   â””â”€â”€ qa_agent.py
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ review_tools.py
â”‚   â””â”€â”€ qa_tools.py
â”œâ”€â”€ orchestrator/
â”‚   â””â”€â”€ multi_agent_router.py
â”œâ”€â”€ .env
â”œâ”€â”€ app.py (Chainlit entry)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ environment.yml
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup

### ğŸ“¦ Option 1: Conda Environment (Recommended)

```bash
conda env create -f environment.yml
conda activate agent
```

### ğŸ’¡ Option 2: Pip Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: .\venv\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸ” Configure Environment
Create a `.env` file:
```env
GITHUB_TOKEN=ghp_XXXXXXXXXXXXXXXXXXXXX
```

---

##  Run the Agent System

```bash
chainlit run app.py
```
Then open [http://localhost:8000](http://localhost:8000)

---

## Example Queries

- "Search for top papers on temporal graph neural networks."
- "Review this PDF in enhanced mode."( to be implemented)
- "Give me a visual summary of this paper."
- "What is a temporal point process?"

---

## Limitations

- Azure Inference requires correct PAT and model permissions
- Some models do not support auto tool calling (manual fix required)
- Large PDFs are chunked to avoid context overflows

---

## Credits

- Microsoft AutoGen
- GitHub Models on Azure Inference
- Chainlit.io

---

## ğŸ“œ License

MIT License. Use freely, modify creatively, contribute collaboratively.

---

## ğŸ¤– Future Work

- [ ] Add memory and persistent context
- [ ] Integrate PubMed, Semantic Scholar APIs
- [ ] Stream output for long responses
- [ ] Full PDF upload pipeline via Chainlit