# Multi-Agent Research Assistant

An advanced research assistant powered by **AutoGen AgentChat**, **Microsoft Azure Semantic Kernel**, and **Chainlit UI**, simulating the full academic workflow from literature search to document analysis.

> âš™ï¸ **Built for the Microsoft AI Agent Hackathon** â€” this system demonstrates **intelligent agent routing**, **modular architecture**, **semantic reasoning**, and **tool-enhanced AI interactions**, all using **Azure-native services**.

---

## ğŸ§© Overview

![image](https://github.com/user-attachments/assets/d7a519e2-2137-4558-9971-78cf928ac052)


The system supports **two core tabs** in the UI:

- **ğŸ” Search Assistant**
  - Handles general or thematic paper queries.
  - Routes intelligently via **Semantic Kernel planner**:
    - â¤ For classic/foundational questions â†’ **Multi-Judge Agent**
    - â¤ For real-time or code-related queries (e.g., â€œ2024â€, â€œbenchmarkâ€, â€œwith codeâ€) â†’ **Literature Review Agent** with Chain-of-Thought (CoT) and external tools.

- **ğŸ“„ QA Assistant**
  - Supports document-based Q&A using a **robust RAG pipeline**.
  - Allows **uploading up to 10 files**, supporting `PDF`, `DOC`, `TXT`, etc.
  - Retrieves context using **chunking + cosine similarity** and enriches answers with **web search + citation**.

---

## âš™ï¸ Multi-Judge Recommendation System

Instead of relying on a single LLM, this system **concurrently dispatches three expert judge agents** with distinct scoring dimensions:

| Judge Agent         | Responsibility                                             |
|---------------------|-------------------------------------------------------------|
| ğŸ§  Semantic Judge    | Evaluates **semantic relevance** to user query              |
| ğŸŒ± Innovation Judge | Scores **novelty and originality** of contributions         |
| ğŸ“ˆ Impact Judge     | Assesses **influence**, e.g., citation potential or impact  |

Each judge **independently retrieves** papers using arXiv/Web tools and returns scores and justifications.

A **Final Judge** agent aggregates the results through **reasoned synthesis**, producing a diverse, stable, and query-aligned ranked list.  
> This panel-style evaluation increases **robustness**, encourages **diversity**, and mirrors how academic peer review committees operate.

---

## ğŸš€ Features & Highlights

| Category               | Description                                                                 |
|------------------------|-----------------------------------------------------------------------------|
| ğŸ§  Semantic Routing     | SK-powered `FunctionCallingStepwisePlanner` dynamically selects the best agent |
| âš–ï¸ Multi-Judge Voting  | 3 judges + 1 aggregator create a robust, diverse ranking system               |
| ğŸ” Real-Time Retrieval | Uses arXiv + DuckDuckGo via **NER-enhanced** keyword extraction               |
| ğŸ“š RAG Q&A             | Upload up to 10 files, chunked + embedded via LangChain + Chroma             |
| ğŸŒ External Search     | Web results are retrieved, cited, and appended to Q&A results                 |
| ğŸ§© Modular Architecture| Fully decoupled agents for ease of customization and future integration       |
| â˜ï¸ Azure Native        | Uses `AzureChatCompletion`, integrated with GitHub-hosted GPT-4o models       |

---

## ğŸ› ï¸ Tech Stack

| Layer             | Tools Used                                                                 |
|------------------|-----------------------------------------------------------------------------|
| Agent Framework   | `AutoGen AgentChat`, `Semantic Kernel`, `FunctionTool`                     |
| LLM Backend       | Azure OpenAI (`AzureChatCompletion`, GPT-4o-mini)                          |
| Routing           | `FunctionCallingStepwisePlanner` for intelligent skill invocation          |
| Retrieval         | `arxiv.org API`, `DuckDuckGo`, `NER-based keyword extraction`              |
| Document QA       | `LangChain`, `Chroma`, `PyMuPDF`, `unstructured`, `cosine similarity`      |
| UI & UX           | `Chainlit` interface with interactive tabs                                 |
| Data Security     | `.env`, `dotenv`, Azure key + PAT protection                               |

---

## ğŸ“‚ Codebase Structure

```
project_root/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ multi_judge_agent.py         # Concurrent judge execution
â”‚   â”œâ”€â”€ literature_agent.py          # Web/arXiv retriever
â”‚   â””â”€â”€ document_agent.py            # Chroma + LangChain RAG
â”œâ”€â”€ orchestrator/
â”‚   â””â”€â”€ sk_router_planner.py         # SK-based semantic router
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ arxiv_search_tool.py         # With NER topic extraction
â”‚   â”œâ”€â”€ qa_tools.py
â”‚   â””â”€â”€ review_tools.py
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ prompt_template.py
â”œâ”€â”€ public/                          # Chainlit UI
â”œâ”€â”€ app.py                           # Entry point
â”œâ”€â”€ environment.yml / requirements.txt
â”œâ”€â”€ session_manager.py / test.py
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### ğŸ“¦ Conda

```bash
conda env create -f environment.yml
conda activate agent
```

### ğŸ’¡ Virtualenv

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## ğŸ” Environment Configuration

```env
AZURE_OPENAI_KEY=your-azure-key
GITHUB_TOKEN=ghp_XXXXXXXXXXXXXXXXX
```

---

## â–¶ï¸ Run the System

```bash
chainlit run app.py
```

Then open [http://localhost:8000](http://localhost:8000)

---

## ğŸ’¬ Sample Prompts

- "Recommend classic deep learning papers."
- "Find the latest 2024 papers on Graph Transformers with code."
- "Upload and summarize these three PDFs."
- "Compare the novelty of these two LLM papers."

---

## âœ… Hackathon Evaluation Alignment

| Judging Area           | How This Project Aligns                                                                                  |
|------------------------|----------------------------------------------------------------------------------------------------------|
| ğŸ’¡ Innovation           | Panel-based multi-agent scoring + SK planner + NER + CoT pipeline + RAG + tool-calling                  |
| ğŸŒ Impact               | Supports researchers, educators, and students in discovering, comparing, and understanding literature   |
| ğŸ§° Usability            | Real-world file support, Human-in-the-Loop citations, CoT, RAG, external data sources                    |
| ğŸ§  Solution Quality     | Full modular repo, semantic planner, test suite, robust chunking, clear separation of agents            |
| â˜ï¸ MS Tech Focus        | Azure-hosted LLMs, Semantic Kernel routing, AutoGen agents, GitHub model integration                     |

---

## ğŸ“ˆ Future Work

- [ ] Stream CoT steps to front-end
- [ ] Add PubMed + Semantic Scholar APIs
- [ ] Visual summary support for uploaded PDFs
- [ ] Score calibration via user feedback loop

---

## ğŸ™Œ Acknowledgements

- Microsoft AutoGen Team
- Semantic Kernel & Azure AI Agent Team
- Chainlit.io contributors
- All open-source tools & research APIs used
